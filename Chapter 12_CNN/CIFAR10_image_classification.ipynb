{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5npUx1_twsV"
   },
   "source": [
    "# Image Classification với tập dữ liệu CIFAR-10\n",
    "Notebook này sẽ thực hiện việc phân lớp ảnh từ [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  Tập dữ liệu bao gồm ảnh của các đối tượng: airplanes, dogs, cats, and other objects. Bước đầu tiên là tiền sử lý ảnh, sau đó huấn luyện một mạng convolutional neural network trên tập dữ liệu. Dữ liệu ảnh cần được normalized và labels được encoded dạng one-hot vector. Một vài tập dữ liệu khác để thực hành có thể download tại [đây](http://rodrigob.github.io/are_we_there_yet/build/#datasets)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yu0rk6s8deK"
   },
   "source": [
    "## Thu thập dữ liệu\n",
    "Chạy mã trong cell dưới đây để tải về CIFAR-10 tại [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoLb4fLMtwsW"
   },
   "source": [
    "#### Tham khảo:\n",
    "- [CIFAR-10/CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html): Tập dữ liệu gồm 80 triệu ảnh kích thước nhỏ đã được gán nhãn. \n",
    "- [urlretrieve lib](https://docs.python.org/3.0/library/urllib.request.html): Thư viện thực hiện sao chép một đối tượng từ internet thông qua url về máy tính nếu đối tượng đó chưa tồn tại trên bộ nhớ\n",
    "- [tarfile lib](https://docs.python.org/2/library/tarfile.html): Đọc và ghi file nén dạng tar, gzip, bz2.\n",
    "- [tqdm lib](https://pypi.python.org/pypi/tqdm): Tạo thanh Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6DfdWmowDmr"
   },
   "outputs": [],
   "source": [
    "# cài đặt thư viện tqdm\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htikb9Y4twsX"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    Kiểm tra xem file dữ liệu (zip) được tải về chưa\n",
    "    nếu chưa, tải về tại \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" với tên cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjEVM-0Ftwsa"
   },
   "source": [
    "## Một số nội dung trước khi bắt đầu với CIFAR-10\n",
    "\n",
    "### Tham khảo:\n",
    "- [python pickle](https://docs.python.org/3/library/pickle.html): Thư viện cài đặt các phương thức serializing and de-serializing cho các đối tượng Python, ghi xuống thành file nhị phân.\n",
    "- [numpy reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html): Thay đổi shape của một mảng numpy mà không làm thay đổi dữ liệu.\n",
    "- [numpy transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html): Hoán đổi chiều của mảng numpy.\n",
    "- [Giải thích numpy transpose với mảng nhiều chiều](https://stackoverflow.com/questions/32034237/how-does-numpys-transpose-method-permute-the-axes-of-an-array)\n",
    "- [tensorflow conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d): Tài liệu về lớp convolution trong tensorflow. Lưu ý đối số mô tả dữ liệu đầu vào \"data_format\" (\"NHWC\": [batch, height, width, channels], \"NCHW\": [batch, channels, height, width]).\n",
    "- [Giải thích khái niệm row major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAItraHFtwsb"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctt4rEJitwsd"
   },
   "source": [
    "### Danh sách các files trong CIFAR-10 \n",
    "\n",
    "![](https://github.com/anhngml/CIFAR10-img-classification-tensorflow/raw/6d33faa5ffc4c48a6553966ad44f15f98d003a34/list_of_batch_files.png)\n",
    "\n",
    "Như ảnh trên, tập dữ liệu được chia thành nhiều batches nhằm chánh trường hợp máy tính gặp lỗi **out of memory**. CIFAR-10 bao gồm 5 batches, đặt tên `data_batch_1`, `data_batch_2`, etc..\n",
    "\n",
    "\n",
    "### Tìm hiểu dữ liệu gốc \n",
    "\n",
    "Một batch dữ liệu là một tensor (10000 x 3072) chiều dưới dạng numpy array, trong đó con số chỉ số lượng cột, (10000), thể hiện số mẫu dữ liệu. Như đã nêu trong [CIFAR-10/CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), vector hàng, (3072) biểu diễn một ảnh màu 32x32 pixels. Vì notebook này dự định sử dụng CNN cho bài toán phân lớp,vector hàng, (3072), là không phù hợp để làm input đưa vào mạng. Để đưa một dữ liệu ảnh vào mô hình CNN, kích thước của tensor biểu diễn một ảnh cần có dạng (width x height x num_channel) hoặc (num_channel x width x height), phụ thuộc vào lựa chọn định dạng dữ liệu đầu vào (xem tại [tensorflow conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)). Notebook này lựa chọn định dạng mặc định của tensorflow.\n",
    "\n",
    "\n",
    "### Nhãn của dữ liệu\n",
    "\n",
    "Dữ liệu nhãn gồm một list của 10000 số trong khoảng 0-9, tương ứng với một trong 10 lớp trong CIFAR-10. \n",
    "\n",
    "* **airplane**\n",
    "* **automobile**\n",
    "* **bird**\n",
    "* **cat**\n",
    "* **deer**\n",
    "* **dog**\n",
    "* **frog**\n",
    "* **horse**\n",
    "* **ship**\n",
    "* **truck**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l026DnSGtwse"
   },
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6jX-J9atwsg"
   },
   "source": [
    "### Reshape về kích thước phù hợp cho CNN\n",
    "\n",
    "Vector hàng (3072) có cùng số lượng phần tử với ảnh màu 32\\*32\\*3==3072. Để reshape vector hàng, (3072), cần thực hiện 2 bước. Bước **đầu tiên** là sử dụng hàm **reshape** của numpy, và bước **thứ hai** sử dụng hàm **transpose** cũng của numpy.\n",
    "\n",
    "Theo định nghĩa, hàm **reshape** thay đổi shape của một mảng mà không làm thay đổi dữ liệu. **Reshape** Có thể chia thành các bước chi tiết dưới đây: \n",
    "\n",
    "1. Chia vector hàng (3072) thành 3 phần. Mỗi phần tương ứng với một kênh màu.\n",
    "  - kết quả là tensor với kích thước (3 x 1024)\n",
    "2. Chia tensor thu được từ bước 1 thành 32. 32 ở đây chính là kích thước chiều rộng của anh.\n",
    "  - kết quả là tensor (3 x 32 x 32)\n",
    "\n",
    "Đối số cho hàm **reshape** sẽ là một tuple, (10000, 3, 32, 32).\n",
    "\n",
    "Chưa xong, bây giờ tập dữ liệu ảnh được biểu diễn dạng (num_channel, width, height). Tuy nhiên, **đây không phải là shape mà tensorflow và matplotlib mong đợi**, mà là (width, height, num_channel). Vậy cần phải hoán đổi thứ tự của mỗi trục, bằng cách sử dụng hàm **transpose**.\n",
    "\n",
    "<img src=\"https://github.com/anhngml/CIFAR10-img-classification-tensorflow/raw/6d33faa5ffc4c48a6553966ad44f15f98d003a34/reshape-transpose.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yJVlaEStwsh"
   },
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3huvVzmtwsj"
   },
   "source": [
    "## Khám phá dữ liệu\n",
    "\n",
    "Hiểu tập dữ liệu là một phần quan trọng trong xây dựng hệ thống prediction trên dữ liệu. Thử nghiệm đoạn code sau và thử thay đổi tham số `batch_id` và `sample_id`. `batch_id` là id của mỗi batch (1-5). `sample_id` là id của một cặp sample - label trong batch.\n",
    "\n",
    "Hàm display_stats cho biết các thông tin của từng batch:\n",
    "- \"Có những nhãn nào tất cả?\"\n",
    "- \"Miền giá trị của mỗi dữ liệu ảnh?\"\n",
    "- \"Các nhãn là tuần tự hay ngẫu nhiên?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Watxjn4jtwsj"
   },
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "id": "_HxKLaR6twsl",
    "outputId": "60be9340-1a30-44cb-ec4c-864e0b0136eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd04f62e4e0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 249
      },
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 7000\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JJ3qreFtwso"
   },
   "source": [
    "## Cài đặt hàm tiền xử lý dữ liệu\n",
    "### Normalize\n",
    "**Min-Max Normalization**\n",
    "- phương pháp này đơn giản chỉ thực hiện việc đưa giá trị của x về khoảng giữa 0 và 1.\n",
    "- y = (x-min) / (max-min)\n",
    "\n",
    "**Tham khảo**\n",
    "- [Min-Max Normalization](https://www.quora.com/What-is-the-meaning-of-min-max-normalization)\n",
    "- [Xem \"tại sao phải normalizing inputs\" / deeplearning.ai - Andrew Ng.](https://www.youtube.com/watch?v=FDCfw-YqWTE)\n",
    "- [Exploding, Vainishing Gradient descent / deeplearning.ai - Andrew Ng.](https://www.youtube.com/watch?v=qhXZsFVxGKo)\n",
    "\n",
    "Hàm `normalize` nhận một ảnh, `x`, và trả về một mảng Numpy đã normalized. Giá trị ban đầu của dữ liệu được biến đổi về khoảng 0 đến 1, nhưng không làm thay đổi kích thước, hình dạng mảng. Câu trả lời đơn giản cho tại sao cần normalization liên quan đến hàm kích hoạt.\n",
    "\n",
    "Ví dụ, hàm sigmoid activation nhận giá trị vào và trả ra giá trị mới trong khoảng 0 đến 1. Khi giá trị đầu vào lớn, giá trị trả ra tiến gần đến 1. Tương tự, khi giá trị đầu vào nhỏ, đầu ra gần đến 0. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Một ví dụ khác, hàm kích hoạt ReLU nhận giá trị đầu vào và đưa ra giá trị mới trong khoảng từ 0 đến dương vô cùng. Khi đầu vào lớn, giá trị đầu ra tăng một cách tuyến tính. Tuy nhiên, khi đầu vào nhỏ, giá trị trả về tiến đến 0. \n",
    "\n",
    "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_4/Relu.jpeg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "bây giờ, xem xét dữ liệu ảnh, mọi giá trị ban đầu thuộc khoảng 0 đến 255. Khi ảnh chuyền qua hàm sigmoid, giá trị gần như luôn luôn gần với 1, và khi chuyền qua ReLu, giá trị trả ra luôn rất lớn. Khi thực hiện lan truyền ngược để tối ưu mạng, dễ dẫn đến bùng nổ gradient dẫn đến bước cập nhật trọng số \"kinh khủng\". Để tránh vấn đề kể trên, tốt nhất là nên đưa giá trị về khoảng 0 và 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BaPHxIs_twso"
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xUZBBvUtwsp"
   },
   "source": [
    "### One-hot encode\n",
    "\n",
    "Vì output của mô hình thể hiện xác suất một ảnh thuộc vào từng lớp, nên nó cần ở dạng một vector có số thành phần bằng với số lớp. Cụ thể, CIFAR-10 có 10 lớp đối tượng khác nhau của ảnh, vậy cần vector có kích thước cũng là 10. Mỗi thành phần của vector thể hiện kết quả dự đoán là xác suất thuộc về mỗi lớp.\n",
    "\n",
    "Mô hình cần so sánh dự đoán đầu ra với nhãn đúng. Nghĩa là hình dạng của nhãn cũng cần phải biến đổi thành một vector kích thước bằng 10. Bởi vì nhãn là ground truth, chúng ta đặt giá trị 1 cho thành phần tương ứng với nhãn của vector.\n",
    "\n",
    "**`one_hot_encode`** nhận đầu vào, **`x`**, là một list các nhãn (ground truth). Tổng số thành phần của list là tổng số samples trong một batch. **`one_hot_encode`** trả về một tensor kích thước bằng 2, với số dòng là kích thước batch, tổng số cột là số lớp của ảnh.\n",
    "\n",
    "#### Tham khảo\n",
    "- [one hot encoding](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp-o5Nuxtwsq"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IngSxZUBtwss"
   },
   "source": [
    "## Tiền xử lý dữ liệu\n",
    "\n",
    "Đoạn code dưới đây dùng hàm đã cài đặt phía trên, normalize and one_hot_encode, để tiến hành tiền xử lý toàn bộ tập dữ liệu.\n",
    "Chạy cell bên dưới sẽ thực hiện tiền xử lý toàn bộ tập CIFAR-10 và lưu xuống file, đồng thời phân chia 10% dữ liệu huấn luyện cho validation. \n",
    "\n",
    "<img src=\"https://github.com/anhngml/CIFAR10-img-classification-tensorflow/raw/6d33faa5ffc4c48a6553966ad44f15f98d003a34/train-valid-test%20split.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOaKv0Kitwst"
   },
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEBYthcVtwsv"
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImWak_U-twsw"
   },
   "source": [
    "## Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uw1hKTd6twsx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mbam_FbGtws0"
   },
   "source": [
    "## Tensorflow cơ bản\n",
    "\n",
    "Trước khi xây dựng mạng và tiến hành huấn luyện, cần xem qua cách thức mà Tensorflow làm việc. \n",
    "\n",
    "### Tensorflow Packages\n",
    "Tensorflow bao gồm nhiều packages. Thậm chí có nhiều modules có chức năng tương tự nhau. Ví dụ, tf.nn.conv2d và tf.layers.conv2d đều là phép toán 2-D convolutional. Dưới đây là mục đích của mỗi packages.\n",
    "\n",
    "#### tf.nn: lower level APIs cho neural network\n",
    "  - mỗi APIs thuộc package này có một mục đích duy nhất\n",
    "  - ví dụ, để áp dụng activation function ngay sau conv2d, cần gọi riêng biệt từng API\n",
    "  - cần thiết lập rất nhiều tham số một cách manually\n",
    "\n",
    "#### tf.layers: higher level APIs for neural network\n",
    "  - mỗi APIs thuộc package này thực hiện một tiến trình được xắp xếp trước một cách hợp lý\n",
    "  - ví dụ, để áp dụng activation function ngay sau conv2d, không cần gọi riêng biệt các APIs, thay vào đó, conv2d API thuộc package này có sẵn đối số gọi hàm activation\n",
    "  - mỗi APIs thuộc package có sẵn nhiều đối số được cấu hình mặc định\n",
    "  \n",
    "#### tf.contrib: contrib module bao gồm các APIs đang được thí nghiệm và dễ bị thay đổi\n",
    "  - như mô tả trong tài liệu của tensorflow, package này cung cấp các APIs đang ở mức thí nghiệm\n",
    "  - rất có thể sẽ tìm thấy nhiều APIs tiện dụng\n",
    "  - nên tìm kiếm các thuật toán trong package này nếu không thể thấy một API có chức năng tương tự ở các gói chính thức\n",
    "  - nhiều tính năng có thể sớm được đưa vào TensorFlow, nhưng có thể coi chúng là đang được xây dựng\n",
    "\n",
    "Chúng ta sẽ sử dụng APIs thuộc các packages khác nhau, vì thế cần phải làm quen với các cách sử dụng API khác nhau. Dưới đây là danh sách các APIs sẽ được sử dụng để cài đặt toàn bộ model.\n",
    "\n",
    "#### Tham khảo\n",
    "\n",
    "- [Stanford CS20 'Tensorflow for Deep Learning Research'](https://web.stanford.edu/class/cs20si/syllabus.html)\n",
    "\n",
    "### Quy trình làm việc của Tensorflow\n",
    "\n",
    "Từ tài liệu chính thức của Tensorflow, **TensorFlow** sử dụng một **dataflow graph** để biểu diễn quá trình tính toán. Dẫn đến để lập trình với low-level APIs, chúng ta cần **định nghĩa dataflow graph**, **sau đó** khởi tạo một TensorFlow **session để thực hiện tính toán một hoặc nhiều phần của graph** trên một tập các devices.\n",
    "\n",
    "**Dataflow** là một mô hình lập trình thông dụng cho **parallel computing**. Trong một dataflow graph, các nodes biểu diễn một đơn vị tính toán, và các cạnh biểu diễn dữ liệu được sử dụng hoặc được tạo ra bởi một đơn vị tính toán khác. Ví dụ, trong một TensorFlow graph, phép toán tf.matmul sẽ tương ứng với một node với 2 cạnh đi vào node đó (hai matrices sẽ được nhân) và một cạnh đi ra từ node (kết quả của phép nhân).\n",
    "\n",
    "Đa phần các chương trình **TensorFlow** bắt đầu với bước xây dựng dataflow graph. Trong bước này, chúng ta sử dụng đối tượng TensorFlow tf.Operation (node) và tf.Tensor (cạnh) và đưa chúng vào một tf.Graph. **TensorFlow cung cấp một graph mặc định** là một **đối số đầu vào cho mọi hàm API trong cùng một context**.\n",
    "\n",
    "Phương thức **tf.Session.run** dùng để **chạy một tf.Operation hoặc đánh giá một tf.Tensor**. Chúng ta có thể đưa vào một hoặc nhiều đối tượng tf.Operation hoặc tf.Tensor cho hàm tf.Session.run, và TensorFlow sẽ chạy các phép toán cần thiết để đưa ra kết quả.\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/versions/r1.3/images/tensors_flowing.gif\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "#### tham khảo\n",
    "- [Tensorflow Architecture](https://www.tensorflow.org/extend/architecture)\n",
    "- [Tensorflow Graphs and Sessions](https://www.tensorflow.org/versions/r1.3/programmers_guide/graphs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pGtVdXgtws1"
   },
   "source": [
    "## Build mạng\n",
    "\n",
    "Ảnh dưới mô tả mô hình được xây dựng trong notebook này.\n",
    "\n",
    "<img src=\"https://github.com/anhngml/CIFAR10-img-classification-tensorflow/raw/6d33faa5ffc4c48a6553966ad44f15f98d003a34/conv_model.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46l5TNmKtws2"
   },
   "source": [
    "### Chuẩn bị đầu vào cho Model\n",
    "\n",
    "#### tham khảo\n",
    "- [Tensorflow Data Type](https://www.tensorflow.org/api_docs/python/tf/DType)\n",
    "- [Tensorflow Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    "- [Tensorflow Variable](https://www.tensorflow.org/api_docs/python/tf/Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGEeIxyqtws3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y =  tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_XR5wxFtws5"
   },
   "source": [
    "### Tạo mô hình Convolutional\n",
    "\n",
    "Toàn bộ mô hình bao gồm 14 layers.\n",
    "\n",
    "1. Convolution với 64 filters kích thước (3x3)\n",
    "2. Max Pooling với\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "3. Convolution với 128 filters kích thước (3x3)\n",
    "4. Max Pooling với\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "5. Convolution với 256 filters kích thước (3x3)\n",
    "6. Max Pooling với\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "7. Convolution với 512 filters kích thước (3x3)\n",
    "8. Max Pooling với\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "9. Flattening (duỗi phẳng) 3-D output của lớp convolutional cuối cùng.\n",
    "10. Fully Connected Layer với 128 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "11. Fully Connected Layer với 256 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "12. Fully Connected Layer với 512 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "13. Fully Connected Layer với 1024 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "14. Fully Connected Layer với 10 units (tổng số lớp của dữ liệu ảnh)\n",
    "\n",
    "ảnh dưới đây mô tả phép convolutionđược cài đặt trong tensorflow với tensor có dạng [Channel x Width x Height]. \n",
    "\n",
    "<img src=\"https://github.com/anhngml/CIFAR10-img-classification-tensorflow/raw/6d33faa5ffc4c48a6553966ad44f15f98d003a34/convolving.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "\n",
    "#### tham khảo\n",
    "- [Tensorflow Conv2D under tf.nn](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)\n",
    "- [Tensorflow ReLU under tf.nn](https://www.tensorflow.org/api_docs/python/tf/nn/relu)\n",
    "- [Tensorflow Max Pooling under tf.nn](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool)\n",
    "- [Tensorflow Dropout under tf.nn](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)\n",
    "- [Tensorflow Batch Normalization under tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization)\n",
    "- [Tensorflow Flatten under tf.contrib](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten)\n",
    "- [Tensorflow Fully Connected under tf.contrib](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected)\n",
    "- [Batch Normalization (the original paper)](https://arxiv.org/abs/1502.03167)\n",
    "- [Why does Batch Norm works? / deeplearning.ai - Andrew Ng.](https://www.youtube.com/watch?v=NbGUU6ZYtus)\n",
    "- [Dropout (the original paper)](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)\n",
    "- [Understanding Dropout / deeplearning.ai - Andrew Ng.](https://www.youtube.com/watch?v=ARq74QuavAo)\n",
    "- [Dropout in (Deep) Machine learning](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)\n",
    "- [What is the meaning of flattening step in a convolutional neural network?](https://www.quora.com/What-is-the-meaning-of-flattening-step-in-a-convolutional-neural-network)\n",
    "- [Convolutional Neural Networks (CNNs / ConvNets) - CS231n](http://cs231n.github.io/convolutional-networks/)\n",
    "- [Visualizing and Understanding Convolutional Networks](https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)\n",
    "- [Evaluation of the CNN design choices performance on ImageNet-2012](https://github.com/ducha-aiki/caffenet-benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85seXkHqtws6"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ehnhvKMtws-"
   },
   "source": [
    "### Siêu tham số ( Hyperparameters)\n",
    "\n",
    "* `epochs`: số vòng lặp cho đến khi kết thúc huấn luyện mạng hoặc bắt đầu sảy ra overfitting\n",
    "* `batch_size`: kích thước lớn nhất mà bộ nhớ của máy tính có thể đáp ứng. Đa số chọn các kích thước phổ biến\n",
    "* `keep_probability`: xác suất bỏ một node sử dụng dropout\n",
    "* `learning_rate`: hệ số tốc độ cập nhật trọng số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtOzhU9vtws_"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "keep_probability = 0.7\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pe0gJwRBtwtB"
   },
   "source": [
    "### Cost Function & Optimizer\n",
    "\n",
    "- [Tensorflow Softmax Cross Entropy with Logits](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)\n",
    "- [Tensorflow Reduce Mean](https://www.tensorflow.org/api_docs/python/tf/reduce_mean)\n",
    "- [Tensorflow Optimizers](https://www.tensorflow.org/api_guides/python/train)\n",
    "- [Tensorflow Equal](https://www.tensorflow.org/api_docs/python/tf/equal)\n",
    "- [Tensorflow Cast](https://www.tensorflow.org/api_docs/python/tf/cast)\n",
    "- [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/)\n",
    "- [Optimization for Training Deep Models](http://www.deeplearningbook.org/contents/optimization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x162sBzEtwtB"
   },
   "outputs": [],
   "source": [
    "logits = conv_net(x, keep_prob)\n",
    "model = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJASiXSXtwtC"
   },
   "source": [
    "## Huấn luyện Neural Network\n",
    "\n",
    "Cần định nghĩa hàm cost, optimizer và accuracy..\n",
    "- **cost**:  \n",
    "   - tf.reduce_mean returns => Một **Tensor** cần được làm giảm dần\n",
    "- **optimizer**:  \n",
    "   - tf.train.AdamOptimizer returns => Một **Operation**\n",
    "- **accuracy**: \n",
    "   - tf.reduce_mean returns => **Tensor**\n",
    "\n",
    "Hàm tf.Session.run chạy một \"step\" tính toán của TensorFlow, bằng cách chạy một phần graph cần thiết để thực hiện mọi Operation và tính toán giá trị của mỗi Tensor, thay thế giá trị trong feed_dict cho mỗi giá trị đầu vào tương ứng.\n",
    "\n",
    "Một khi đã xây dựng xong graph, chỉ cần feeding data cho graph chỉ định kết quả cần trả về.\n",
    "\n",
    "\n",
    "\n",
    "#### tham khảo\n",
    "- [Tensorflow Session run function](https://www.tensorflow.org/api_docs/python/tf/Session#run)\n",
    "- [Tensorflow tf.reduce_mean](https://www.tensorflow.org/api_docs/python/tf/reduce_mean)\n",
    "- [Tensorflow tf.train.AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_oSslljtwtF"
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vDYUi0_twtG"
   },
   "source": [
    "### Hiển thị thống kê\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKMb6n0TtwtG"
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlxXLNNItwtI"
   },
   "source": [
    "### Huấn luyện Mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLxeqXXJtwtI"
   },
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAHgelKOtwtL"
   },
   "outputs": [],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIxuDt4itwtN"
   },
   "source": [
    "# Checkpoint\n",
    "Model đã được ghi xuống ổ đĩa.\n",
    "## Kiểm thử Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeCJEwQPtwtO"
   },
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "    label_names = _load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "\n",
    "        axies[image_i][0].imshow(feature*255)\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRJG6Fz9twtP"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "batch_size = 64\n",
    "n_samples = 10\n",
    "top_n_predictions = 5\n",
    "\n",
    "def test_model():\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('input_x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('output_y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s72blenbtwtT"
   },
   "source": [
    "## Một vài Models khác và Accuracies của chúng trên CIFAR-10\n",
    "[Classification datasets results](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR10_image_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
